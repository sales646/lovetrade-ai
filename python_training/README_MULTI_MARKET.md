# ğŸŒ Multi-Market Training Guide

## Cross-Market Transfer Learning fÃ¶r RL Trading

Detta system trÃ¤nar **en enda policy** pÃ¥ bÃ¥de aktier (NASDAQ) och krypto (Binance) samtidigt fÃ¶r att skapa en robust agent som hanterar olika volatilitetsregimer.

---

## ğŸ“Š VarfÃ¶r Multi-Market Training?

### FÃ¶rdelar

âœ… **Volatilitetsrobusthet**: LÃ¤r sig hantera bÃ¥de lÃ¥g (aktier) och hÃ¶g (krypto) volatilitet  
âœ… **BÃ¤ttre generalisering**: LÃ¤r sig underliggande marknadsmekanismer, inte bara specifika instrument  
âœ… **24/7 anpassning**: FÃ¶rstÃ¥r skillnaden mellan sessions-baserad (aktier) och kontinuerlig (krypto) handel  
âœ… **Transfer learning**: Samma princip som multi-sprÃ¥k trÃ¤ning fÃ¶r LLMs  
âœ… **Robustare policies**: Ã–verreagerar inte pÃ¥ spikes, vet nÃ¤r man **inte** ska handla  

### Teknisk Grund

PPO och BC Ã¤r **inte bundna till specifika marknader** â€” de lÃ¤r sig:
- Momentum och mean-reversion patterns
- Volymkluster och likviditetsskiften
- Risk-reward balans Ã¶ver olika regimer

---

## ğŸ”§ Teknisk Implementation

### 1ï¸âƒ£ Market Type Encoding

Varje observation innehÃ¥ller en **market_type** feature:

```python
state[50] = 0  # Stock (NASDAQ)
state[51] = 1  # Crypto (Binance)
```

Detta blir ett "context token" som nÃ¤tverket anvÃ¤nder fÃ¶r att skilja mellan marknader.

---

### 2ï¸âƒ£ Normalisering (KRITISKT!)

Eftersom krypto rÃ¶r sig 5â€“10Ã— mer Ã¤n aktier **mÃ¥ste** all data normaliseras:

#### Log-Returns
```python
log_return = ln(P_t / P_{t-1})
```

#### Z-Score Normalisering per Symbol
```python
z_t = (log_return - Î¼_symbol) / Ïƒ_symbol
```

Detta ger **jÃ¤mfÃ¶rbara state-distributioner** mellan marknader.

#### Implementation
- `_compute_symbol_stats()`: BerÃ¤knar mean, std, ATR per symbol vid startup
- `_get_observation()`: Applicerar z-score normalisering pÃ¥ log-returns
- `step()`: AnvÃ¤nder Sharpe-normaliserad reward

---

### 3ï¸âƒ£ Sharpe-Normaliserad Reward

FÃ¶r att undvika att krypto dominerar trÃ¤ningen (pga stÃ¶rre rÃ¶relser):

```python
reward_t = (log_return / Ïƒ_symbol) * position_size * 100
```

Detta gÃ¶r att agenten bedÃ¶mer **riskjusterad vinst**, inte bara "stÃ¶rst vinst = bÃ¤st".

---

### 4ï¸âƒ£ Data Blending

Rekommenderade fÃ¶rhÃ¥llanden:

| Ratio | AnvÃ¤ndningsfall |
|-------|----------------|
| **70/30 Crypto:Stock** | PPO-trÃ¤ning (mer variation â†’ snabbare inlÃ¤rning) |
| **50/50** | BC pretrain (balanserad fÃ¶rstÃ¥else) |
| **30/70 Crypto:Stock** | Finetune fÃ¶r bÃ¶rshandel (mer stabilitet) |

---

## ğŸš€ AnvÃ¤ndning

### Steg 1: HÃ¤mta Data

```bash
# HÃ¤mta krypto-data (1-min, 3 Ã¥r, 17 marknader)
python fetch_binance_data.py

# Uppdatera cache med bÃ¥de stocks + crypto
python preload_data.py
```

### Steg 2: TrÃ¤na Multi-Market Policy

```bash
# Quick training med mixad data
python quick_train.py
```

Environment kommer automatiskt att:
1. Ladda bÃ¥de stock och crypto bars
2. Klassificera symbols (aktier vs krypto)
3. BerÃ¤kna symbol-specifik statistik
4. Applicera normalisering och Sharpe-reward

---

## ğŸ“ˆ TrÃ¤ningsschema

| Fas | Data | Syfte | Epochs |
|-----|------|-------|--------|
| **BC Pretrain** | 50/50 stock + crypto | LÃ¤r basmÃ¶nster | 5kâ€“10k |
| **PPO Train** | 70/30 crypto:stock | LÃ¤r risk/avkastning | 10Mâ€“20M steps |
| **Finetune** | 100% aktier | Anpassa fÃ¶r bÃ¶rsregler | 2kâ€“5k |

---

## ğŸ” Features i State Vector

```python
# Standard features (0-49)
- OHLCV, technical indicators, position state, momentum

# Multi-market features (50-51)
state[50] = market_type        # 0 = stock, 1 = crypto
state[51] = normalized_volatility  # ATR / avg_price
```

Total state dim: **52 features**

---

## ğŸ’¡ Advanced Tricks

### Domain Randomization
Applicera smÃ¥ slumpade distorsioner:
- Fees: Â±0.1%
- Slippage: Â±0.05%
- Delays: Â±1 bar

â†’ Starkare generalisering

### Trading Hours Mask
LÃ¤gg till en signal (0â€“1) fÃ¶r nÃ¤r marknaden Ã¤r Ã¶ppen:
```python
state[52] = is_market_open  # 0 under bÃ¶rs-stÃ¤ngning, 1 annars
```

â†’ Modellen lÃ¤r sig sluta handla utanfÃ¶r Ã¶ppettider

### Multi-Agent Shared Policy (Advanced)
FÃ¶r specialisering med gemensam encoder:
- Shared feature extraction layers
- Separate action heads per marknad

---

## ğŸ“Š Exempel: Symbol Stats

Efter att ha kÃ¶rt `_compute_symbol_stats()`:

```
AAPL:  mean=0.000012, std=0.0234, atr=1.23
BTCUSDT: mean=0.000045, std=0.0789, atr=234.56
```

â†’ Krypto har 3â€“4Ã— hÃ¶gre std â†’ reward normaliseras fÃ¶r rÃ¤ttvis jÃ¤mfÃ¶relse

---

## ğŸ¯ Resultat

En multi-market trÃ¤nad agent:
- Handlar konservativt pÃ¥ aktier (lÃ¤gre volatilitet)
- Reagerar snabbt pÃ¥ krypto (hÃ¶gre volatilitet)
- Vet nÃ¤r man **inte** ska handla (viktigt!)
- Generalizar till nya instrument utan omtrÃ¤ning

---

## ğŸ“š Referenser

- **PPO**: Proximal Policy Optimization (OpenAI)
- **BC**: Behavior Cloning (Imitation Learning)
- **Cross-Domain Transfer**: Samma princip som BERT/GPT multi-sprÃ¥k trÃ¤ning

---

**Tips**: BÃ¶rja med 70/30 crypto:stock fÃ¶r PPO, sedan fintune 100% aktier om du primÃ¤rt handlar NASDAQ.
